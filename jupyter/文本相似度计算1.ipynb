{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_table('csdn_blog_100.csv',sep='\\t',\n",
    "                engine='python',index_col=['_id'],header=None,names=['_id','标题','标签','时间','pv','作者','原创','c'])\n",
    "out['nlp']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg as pseg\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# 加停用词库\n",
    "stopwords = codecs.open('../words/CNstop_words_zh.txt','r',encoding='utf8').readlines()\n",
    "stopwordlist = [ w.strip() for w in stopwords ]\n",
    "# 结巴分词后的停用词性 [标点符号、连词、助词、副词、介词、时语素、‘的’、数词、方位词、代词]\n",
    "stop_flag = ['x', 'c', 'u','d', 'p', 't', 'uj', 'm', 'f', 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(doc):\n",
    "#     结巴分词，去掉停用词\n",
    "    result = []\n",
    "    text = doc\n",
    "    words = pseg.cut(text)\n",
    "    for word, flag in words: \n",
    "        if flag not in stop_flag and word not in stopwords: \n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "ids=[]\n",
    "dockeys=[]\n",
    "# 100篇文档分词，保存\n",
    "for row in out.itertuples():\n",
    "    soup = BeautifulSoup(row.c,'html5lib').getText().strip()\n",
    "    ids.append(row.Index)\n",
    "    word_list = tokenization(soup)\n",
    "    dockeys.append(word_list)\n",
    "    out.loc[out.index==row[0],['nlp']] = ' '.join([w for w in word_list])\n",
    "\n",
    "out.drop(out.columns[[6]], axis=1,inplace=True)\n",
    "out.to_csv('csdn_blog_100_nlp.csv',sep='\\t')\n",
    "try:\n",
    "#     保存文档id列表\n",
    "    import pickle\n",
    "    f = open(\"./csdn_blog_ids_100.dat\", \"wb\")\n",
    "    pickle.dump(ids, f)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('csdn_blog_ids_100.dat保存文件出错')\n",
    "    \n",
    "try:\n",
    "#     保存文档dockeys列表\n",
    "    import pickle\n",
    "    f = open(\"./csdn_blog_dockeys_100.dat\", \"wb\")\n",
    "    pickle.dump(dockeys, f)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('csdn_blog_dockeys_100.dat保存文件出错')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "# 建立词袋模型\n",
    "dictionary = corpora.Dictionary(dockeys)\n",
    "dictionary.save('csdn_blog_100.dict')\n",
    "# print(dictionary)\n",
    "# print(len(dockeys))\n",
    "# for doc in dockey:\n",
    "#     print(len(doc))\n",
    "# 生成词向量\n",
    "corpus = [dictionary.doc2bow(text) for text in dockeys]\n",
    "corpora.MmCorpus.serialize('csdn_blog_100.mm', corpus)\n",
    "# print('len',len(corpus))\n",
    "# print(doc_vectors)\n",
    "# for doc in corpus:\n",
    "#     print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立TF-IDF模型\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]\n",
    "# print(len(tfidf_corpus))\n",
    "# print(len(tfidf_vectors[0]))\n",
    "# for doc in tfidf_vectors:\n",
    "#     print(doc)\n",
    "# 持久化\n",
    "tfidf.save(\"./csdn_blog_model_100.tfidf\")\n",
    "tfidf = models.TfidfModel.load(\"./csdn_blog_model_100.tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4092, 0.17394318),\n",
       " (10107, 0.13801867),\n",
       " (6112, 0.12311725),\n",
       " (4461, 0.11609715),\n",
       " (321, 0.10852387),\n",
       " (1883, 0.094831996),\n",
       " (4926, 0.093249574),\n",
       " (4137, 0.079429373),\n",
       " (12345, 0.076761037),\n",
       " (5670, 0.076752216),\n",
       " (10364, 0.07548704),\n",
       " (823, 0.070422918),\n",
       " (12111, 0.069211349),\n",
       " (2606, 0.064810753),\n",
       " (12242, 0.063527085),\n",
       " (10970, 0.062913775),\n",
       " (1823, 0.061469492),\n",
       " (4485, 0.060431741),\n",
       " (322, 0.057909347),\n",
       " (1834, 0.05714741)]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成tf/idf模型,相似度矩阵\n",
    "index_tfidf = similarities.MatrixSimilarity(tfidf_corpus)\n",
    "index_tfidf.save('csdn_blog_100.index')\n",
    "\n",
    "def tfidfsimilarities(f,index,N=20):\n",
    "    # 求tf/idf模型,相似度\n",
    "    doc=''\n",
    "    with open(f, 'r') as f:\n",
    "        doc = f.read().replace('\\n','')\n",
    "    query=tokenization(doc)\n",
    "    query_bow=dictionary.doc2bow(query)\n",
    "    sims = index[query_bow]\n",
    "    from operator import itemgetter, attrgetter\n",
    "    return sorted(list(enumerate(sims)), key=itemgetter(1),reverse=True)[0:N]\n",
    "\n",
    "def toids(sim,ids):\n",
    "#     语料库ID转换成数据库里的_id\n",
    "    return [(ids[s[0]],s[1]) for s in sim]\n",
    "\n",
    "sim1 = tfidfsimilarities('../测试样本/1.txt',index_tfidf)\n",
    "toids(sim1,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(41, 0.17394318),\n",
       " (78, 0.13801867),\n",
       " (63, 0.12311725),\n",
       " (47, 0.11609715),\n",
       " (0, 0.10852387),\n",
       " (9, 0.094831996),\n",
       " (54, 0.093249574),\n",
       " (43, 0.079429373),\n",
       " (98, 0.076761037),\n",
       " (60, 0.076752216),\n",
       " (81, 0.07548704),\n",
       " (3, 0.070422918),\n",
       " (96, 0.069211349),\n",
       " (21, 0.064810753),\n",
       " (97, 0.063527085),\n",
       " (87, 0.062913775),\n",
       " (6, 0.061469492),\n",
       " (48, 0.060431741),\n",
       " (1, 0.057909347),\n",
       " (8, 0.05714741)]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = tfidfsimilarities('../测试样本/2.txt',index_tfidf)\n",
    "sim3 = tfidfsimilarities('../测试样本/3.txt',index_tfidf)\n",
    "sim4 = tfidfsimilarities('../测试样本/4.txt',index_tfidf)\n",
    "sim5 = tfidfsimilarities('../测试样本/5.txt',index_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建LSI模型，设置主题数为4\n",
    "# lsi = models.LsiModel(doc_vectors, id2word=dictionary, num_topics=4)\n",
    "# lsi.print_topics(4)\n",
    "# lsi_vector = lsi[doc_vectors]\n",
    "# for vec in lsi_vector:\n",
    "#     print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求LSI模型相似度\n",
    "# def tfidfsimilarities(f,lsivectors):\n",
    "#     doc=''\n",
    "#     with open(f, 'r') as f:\n",
    "#         doc = f.read().replace('\\n','')\n",
    "#     query=tokenization(doc)\n",
    "#     query_bow = dictionary.doc2bow(query)\n",
    "#     lsi_bow=lsi[query_bow]\n",
    "#     # lsi模型,相似度\n",
    "#     index = similarities.MatrixSimilarity(lsivectors)\n",
    "#     sims = index[lsi_bow]\n",
    "#     from operator import itemgetter, attrgetter\n",
    "#     return sorted(list(enumerate(sims)), key=itemgetter(1),reverse=True)[0:20]\n",
    "# sim1 = tfidfsimilarities('../测试样本/1.txt',tfidf_vectors)\n",
    "# sim2 = tfidfsimilarities('../测试样本/2.txt',tfidf_vectors)\n",
    "# sim3 = tfidfsimilarities('../测试样本/3.txt',tfidf_vectors)\n",
    "# sim4 = tfidfsimilarities('../测试样本/4.txt',tfidf_vectors)\n",
    "# sim5 = tfidfsimilarities('../测试样本/5.txt',tfidf_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
